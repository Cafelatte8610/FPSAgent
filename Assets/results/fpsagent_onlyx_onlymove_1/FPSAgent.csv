Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
1000,1.0982522,78.5,-0.2472095,-5.3999983469645185,-5.3999983469645185,1.0
2000,1.0985764,99.0,-0.20903938,-9.999997854232788,-9.999997854232788,1.0
3000,1.0963938,99.0,-0.6177486,-9.999997854232788,-9.999997854232788,1.0
4000,1.0961773,99.0,-0.6834567,-9.999997854232788,-9.999997854232788,1.0
5000,1.0951259,96.63636363636364,-1.0386654,-8.648997974395751,-8.648997974395751,1.0
6000,1.0948452,85.0909090909091,-1.2114688,-7.041664878527324,-7.041664878527324,1.0
7000,1.0849638,83.25,-1.313963,-5.915831625461578,-5.915831625461578,1.0
8000,1.0814605,90.0,-1.8271986,-8.140907179225575,-8.140907179225575,1.0
9000,1.0673283,97.2,-1.5184934,-8.728997993469239,-8.728997993469239,1.0
10000,1.0596749,92.0,-2.0871987,-8.365452614697544,-8.365452614697544,1.0
11000,1.0371362,91.72727272727273,-1.8793335,-8.16399805545807,-8.16399805545807,1.0
12000,1.0219232,99.0,-2.4685261,-9.951997900009156,-9.951997900009156,1.0
13000,1.0044135,92.8,-2.5387034,-7.572725317694924,-7.572725317694924,1.0
14000,0.96553063,86.75,-2.4948332,-5.882725542241877,-5.882725542241877,1.0
