Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
1000,2.884107,18.0,-0.08754371,-4.634501814842224,-4.634501814842224,1.0
2000,2.8897817,186.0,-0.09343323,-80.86301040649414,-80.86301040649414,1.0
3000,2.8756573,293.0,-0.581687,-143.93202686309814,-143.93202686309814,1.0
4000,2.8760936,None,-0.6075624,None,None,1.0
5000,2.8493757,None,-1.0369354,None,None,1.0
6000,2.83571,None,-1.4385912,None,None,1.0
7000,2.8129394,None,-1.5737227,None,None,1.0
8000,2.7715275,647.0,-1.9477557,-262.4700417518616,-262.4700417518616,1.0
9000,2.7577305,856.7142857142857,-2.064767,-385.49789476394653,-385.49789476394653,1.0
10000,2.7150552,999.0,-1.8978955,-200.5165309906006,-200.5165309906006,1.0
11000,2.7049716,None,-1.7238642,None,None,1.0
12000,2.6007593,999.0,-2.059489,-352.993052482605,-352.993052482605,1.0
13000,2.5683057,None,-2.062096,None,None,1.0
14000,2.522029,None,-2.4099834,None,None,1.0
15000,2.5288966,620.5,-2.4306912,-108.6105147600174,-108.6105147600174,1.0
16000,2.4297328,None,-2.6464136,None,None,1.0
17000,2.434079,999.0,-2.7187455,-178.9910216331482,-178.9910216331482,1.0
18000,2.3370452,999.0,-2.8487053,-141.7487667053938,-141.7487667053938,1.0
19000,2.3146355,999.0,-3.1160007,-155.999018907547,-155.999018907547,1.0
20000,2.2881444,None,-3.137709,None,None,1.0
21000,2.2688835,999.0,-3.312653,-87.99300807714462,-87.99300807714462,1.0
22000,2.241373,None,-3.3162432,None,None,1.0
