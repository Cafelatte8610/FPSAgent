Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
1000,2.8903577,0.9670542635658915,-0.027711002,-0.8805355321277272,-0.8805355321277272,1.0
2000,2.8903577,0.9921414538310412,-0.027771622,-0.9318813801754133,-0.9318813801754133,1.0
3000,2.8665662,1.3152941176470587,-0.31841314,-0.9202110966507631,-0.9202110966507631,1.0
4000,2.8644674,1.4452554744525548,-0.33738208,-0.9455279407710054,-0.9455279407710054,1.0
5000,2.8295584,2.0091463414634148,-0.56135297,-0.9330389991894856,-0.9330389991894856,1.0
6000,2.822484,2.086153846153846,-0.5961633,-0.9309906728865561,-0.9309906728865561,1.0
